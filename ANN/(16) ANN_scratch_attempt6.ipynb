{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "https://www.fireblazeaischool.in/blogs/neural-network-from-scratch-in-python/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 1 ) Reading Preprocessed CSV files..\n",
      "\t Training dataset loaded..\n",
      "\t Testing dataset loaded..\n",
      "\n",
      "( 2 ) Loading done, splitting into X and Y..\n",
      "\t ( 2.1 ) x_train Shape:  \t (175341, 53)\n",
      "\t ( 2.2 ) y_train Shape:  \t (175341,)\n",
      "\t ( 2.3 ) x_test Shape:  \t (82332, 53)\n",
      "\t ( 2.4 ) y_test Shape:  \t (82332,)\n",
      "( 3 ) Done!\n",
      "PS! Import with: x_train, x_test, y_train, y_test = XY_import()\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from Functions.UNSW_DF import *\n",
    "X, x_test, y, y_test = DF_XY()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "X = X[:1000]\n",
    "y = y[:1000]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "\treturn 1/(1+np.exp(-x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "num_examples = len(X) # training set size\n",
    "nn_input_dim = 53 # input layer dimensionality\n",
    "nn_output_dim = 1 # output layer dimensionality\n",
    "\n",
    "# Gradient descent parameters (I picked these by hand)\n",
    "epsilon = 0.01 # learning rate for gradient descent\n",
    "reg_lambda = 0.01 # regularization strength"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Helper function to evaluate the total loss on the dataset\n",
    "def calculate_loss(model):\n",
    "\tW1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']\n",
    "\t# Forward propagation to calculate our predictions\n",
    "\tz1 = X.dot(W1) + b1\n",
    "\ta1 = np.tanh(z1)\n",
    "\tz2 = a1.dot(W2) + b2\n",
    "\texp_scores = np.exp(z2)\n",
    "\tprobs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\t# Calculating the loss\n",
    "\tcorect_logprobs = -np.log(probs[range(num_examples), y])\n",
    "\tdata_loss = np.sum(corect_logprobs)\n",
    "\t# Add regulatization term to loss (optional)\n",
    "\tdata_loss += reg_lambda/2 * (np.sum(np.square(W1)) + np.sum(np.square(W2)))\n",
    "\treturn 1./num_examples * data_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Helper function to predict an output (0 or 1)\n",
    "def predict(model, x):\n",
    "\tW1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']\n",
    "\t# Forward propagation\n",
    "\tz1 = x.dot(W1) + b1\n",
    "\ta1 = np.tanh(z1)\n",
    "\tz2 = a1.dot(W2) + b2\n",
    "\texp_scores = np.exp(z2)\n",
    "\tprobs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\treturn np.argmax(probs, axis=1)\n",
    "# This function learns parameters for the neural network and returns the model.\n",
    "# - nn_hdim: Number of nodes in the hidden layer\n",
    "# - num_passes: Number of passes through the training data for gradient descent\n",
    "# - print_loss: If True, print the loss every 1000 iterations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def build_model(nn_hdim, num_passes=20000, print_loss=False):\n",
    "\t# Initialize the parameters to random values. We need to learn these.\n",
    "\tnp.random.seed(0)\n",
    "\tW1 = np.random.randn(nn_input_dim, nn_hdim) / np.sqrt(nn_input_dim)\n",
    "\tb1 = np.zeros((1, nn_hdim))\n",
    "\tW2 = np.random.randn(nn_hdim, nn_output_dim) / np.sqrt(nn_hdim)\n",
    "\tb2 = np.zeros((1, nn_output_dim))\n",
    "\n",
    "\t# This is what we return at the end\n",
    "\tmodel = {}\n",
    "\n",
    "\t# Gradient descent. For each batch...\n",
    "\tfor i in range(0, num_passes):\n",
    "\t\t# Forward propagation\n",
    "\t\tz1 = X.dot(W1) + b1\n",
    "\t\ta1 = np.tanh(z1)\n",
    "\t\tz2 = a1.dot(W2) + b2\n",
    "\t\texp_scores = np.exp(z2)\n",
    "\t\tprobs = exp_scores / np.sum(exp_scores, axis=1)\n",
    "\n",
    "\t\t# Backpropagation\n",
    "\t\tdelta3 = probs\n",
    "\t\tdelta3[range(num_examples), y] -= 1\n",
    "\t\tdW2 = (a1.T).dot(delta3)\n",
    "\t\tdb2 = np.sum(delta3, axis=0, keepdims=True)\n",
    "\t\tdelta2 = delta3.dot(W2.T) * (1 - np.power(a1, 2))\n",
    "\t\tdW1 = np.dot(X.T, delta2)\n",
    "\t\tdb1 = np.sum(delta2, axis=0)\n",
    "\n",
    "\t\t# Add regularization terms (b1 and b2 don't have regularization terms)\n",
    "\t\tdW2 += reg_lambda * W2\n",
    "\t\tdW1 += reg_lambda * W1\n",
    "\n",
    "\t\t# Gradient descent parameter update\n",
    "\t\tW1 += -epsilon * dW1\n",
    "\t\tb1 += -epsilon * db1\n",
    "\t\tW2 += -epsilon * dW2\n",
    "\t\tb2 += -epsilon * db2\n",
    "\n",
    "\t\t# Assign new parameters to the model\n",
    "\t\tmodel = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n",
    "\n",
    "\t\t# Optionally print the loss.\n",
    "\t\t# This is expensive because it uses the whole dataset, so we don't want to do it too often.\n",
    "\t\tif print_loss and i % 1000 == 0:\n",
    "\t\t\tprint('quot;Loss after iteration %i: %f\" %(i, calculate_loss(model))')\n",
    "\n",
    "\treturn model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'(range(0, 175341), 0      0\n1      0\n2      0\n3      0\n4      0\n      ..\n995    0\n996    0\n997    0\n998    0\n999    0\nName: label, Length: 1000, dtype: int64)' is an invalid key",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-14-3829fdab0c3f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Build a model with a 3-dimensional hidden layer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbuild_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprint_loss\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-10-d0b0766f45e4>\u001B[0m in \u001B[0;36mbuild_model\u001B[1;34m(nn_hdim, num_passes, print_loss)\u001B[0m\n\u001B[0;32m     21\u001B[0m                 \u001B[1;31m# Backpropagation\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m                 \u001B[0mdelta3\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mprobs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 23\u001B[1;33m                 \u001B[0mdelta3\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnum_examples\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m-=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     24\u001B[0m                 \u001B[0mdW2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0ma1\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mT\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdelta3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m                 \u001B[0mdb2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdelta3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkeepdims\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   2900\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2901\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2902\u001B[1;33m             \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2903\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2904\u001B[0m                 \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   2893\u001B[0m             \u001B[0mcasted_key\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_maybe_cast_indexer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2894\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2895\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2896\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2897\u001B[0m                 \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: '(range(0, 175341), 0      0\n1      0\n2      0\n3      0\n4      0\n      ..\n995    0\n996    0\n997    0\n998    0\n999    0\nName: label, Length: 1000, dtype: int64)' is an invalid key"
     ]
    }
   ],
   "source": [
    "# Build a model with a 3-dimensional hidden layer\n",
    "model = build_model(3, print_loss=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the decision boundary\n",
    "plot_decision_boundary(lambda x: predict(model, x))\n",
    "plt.title('quot;Decision Boundary for hidden layer size 3\"')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}