{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-cac007c6a41e>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mloadtxt\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodels\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mSequential\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayers\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mDense\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;31m#from keras_visualizer import visualizer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     19\u001B[0m \"\"\"\n\u001B[0;32m     20\u001B[0m \u001B[1;31m# pylint: disable=unused-import\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtf2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     22\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdistribute\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from Functions.UNSW_DF import *\n",
    "\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "#from keras_visualizer import visualizer\n",
    "#from ann_visualizer.visualize import ann_viz\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = DF_XY()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=53, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_x=model.predict(X_test) \n",
    "classes_x=np.argmax(predict_x,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_accuracy = []\n",
    "ann_precision = []\n",
    "ann_recall = []\n",
    "ann_f1 = []\n",
    "ann_epochs = []\n",
    "ann_no_of_layers = []\n",
    "\n",
    "for epoch in range(1, 100):\n",
    "    print(f\"\\n## ---------- EPOCH {i} ----------- ##\\n\")\n",
    "    # fit the keras model on the dataset\n",
    "    model.fit(x_train, y_train, epochs=epoch, batch_size=100)\n",
    "    \n",
    "    # predict probabilities for test set\n",
    "    yhat_probs = model.predict(x_test, verbose=0)\n",
    "    # predict crisp classes for test set\n",
    "    yhat_classes = model.predict_classes(x_test, verbose=0)\n",
    "    \n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(y_test, yhat_classes)\n",
    "    ann_accuracy.append(accuracy)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(y_test, yhat_classes)\n",
    "    ann_precision.append(precision)\n",
    "    print('Precision: %f' % precision)\n",
    "\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(y_test, yhat_classes)\n",
    "    ann_recall.append(recall)\n",
    "    print('Recall: %f' % recall)\n",
    "\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(y_test, yhat_classes)\n",
    "    ann_f1.append(f1)\n",
    "    print('F1 score: %f' % f1)\n",
    "    \n",
    "    ann_no_of_layers.append(len(model.layers))\n",
    "    ann_epochs.append(epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the keras model for training and testing data\n",
    "_, train_acc = model.evaluate(x_train, y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Accuracy for training\\t: %.2f' % (train_acc*100))\n",
    "print('Accuracy for testing\\t: %.2f' % (test_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of lists \n",
    "dict = {#'epochs': ann_epochs, \n",
    "        #'number_of_layers': ann_no_of_layers, \n",
    "        'accuracy': ann_accuracy, \n",
    "        'precision': ann_precision, \n",
    "        'f1': ann_f1, \n",
    "        'recall': ann_recall\n",
    "        } \n",
    "    \n",
    "df = pd.DataFrame(dict, index=ann_epochs)\n",
    "# EXPORT AS CSV when done.\n",
    "#df.to_csv('ANN_3_layers.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNSW_barplot(data=df, to_range=29 ,x_label=\"epochs\", y_label=\"Score\", title=\"ANN\", x_size=30, y_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ann_viz(model, title=\"Neural Network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizer(model, format='png', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "557f7a76709d809d5a6b0728b55d2b66cdd1850049e35147309670e9cf1c5b51"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('MastersThesis': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}