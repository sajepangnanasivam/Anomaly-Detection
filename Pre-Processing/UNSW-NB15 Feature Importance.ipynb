{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef8fde93-74c1-4796-a579-41f853bdfeec",
   "metadata": {},
   "source": [
    "# UNSW-NB15 Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c9dc45-8132-47bc-b7fd-78b083d2fc7e",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/khairulislam/unsw-nb15-feature-importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6d8849-bb81-492a-8b81-2903fca94323",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64195a99-1427-4008-ae93-bb83861a52fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d087a5db-801c-4acf-9afe-b8873f0f63e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8d306d-07e3-49c1-8a86-2c5b5a5df569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Reading Train and test dataset.\n",
    "# 2. Check if dataset is reversed.\n",
    "# 3. Drop 'id', and 'attack_cat' columns.\n",
    "def input_train_test():\n",
    "    train = pd.read_csv('UNSW_NB15_training-set.csv')\n",
    "    test = pd.read_csv('UNSW_NB15_testing-set.csv')\n",
    "    \n",
    "    if train.shape < test.shape:\n",
    "        # Reversing the dataset\n",
    "        train, test = test, train\n",
    "        # Dropping the columns\n",
    "        drop_columns = [\"id\", \"attack_cat\"]\n",
    "        print(\"Dropped 'id', and 'attack_cat' columns\")\n",
    "        train.drop(drop_columns, axis=1, inplace=True)\n",
    "        test.drop(drop_columns, axis=1, inplace=True)\n",
    "        print(\"Train and Test sets are reversed, Corrected Shape:\")\n",
    "        print(\"Train shape: \", train.shape)\n",
    "        print(\"Test shape: \", test.shape)\n",
    "    else:\n",
    "        print(\"The dataset, is already reversed\")\n",
    "        print(\"Train shape: \", train.shape)\n",
    "        print(\"Test shape: \", test.shape)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89e46f9-6336-40ff-8d51-d93416135463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identifying object columns and appending them inside cat_cols[]\n",
    "# The training and testing datasets have identical sets of columns. \n",
    "# Fine with getting the column names from only on of the subsets.\n",
    "def get_cat_cols(train):\n",
    "    # Defining an empty list\n",
    "    categorical = []\n",
    "    # Iterating through the columns and checking for columns with datatyp \"Object\"\n",
    "    for col in train.columns:\n",
    "        if train[col].dtype == 'object':\n",
    "            categorical.append(col) # appending \"object\" columns to cat_cols\n",
    "    return categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53045d52-3799-4900-912b-22f15c131853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode(train, test):\n",
    "    for col in get_cat_cols(train):\n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n",
    "        train[col] = le.transform(list(train[col].astype(str).values))\n",
    "        test[col] = le.transform(list(test[col].astype(str).values))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44984fda-744f-40ba-95b5-3f40f87c5f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineer(df):\n",
    "    df.loc[~df['state'].isin(['FIN', 'INT', 'CON', 'REQ', 'RST']), 'state'] = 'others'\n",
    "    df.loc[~df['service'].isin(['-', 'dns', 'http', 'smtp', 'ftp-data', 'ftp', 'ssh', 'pop3']), 'service'] = 'others'\n",
    "    df.loc[df['proto'].isin(['igmp', 'icmp', 'rtp']), 'proto'] = 'igmp_icmp_rtp'\n",
    "    df.loc[~df['proto'].isin(['tcp', 'udp', 'arp', 'ospf', 'igmp_icmp_rtp']), 'proto'] = 'others'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be70ca9-c956-44e9-ac3a-e297f77310a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(train, test, label_encoding=False, scaler=None):\n",
    "    x_train, y_train = train.drop(['label'], axis=1), train['label']\n",
    "    x_test, y_test = test.drop(['label'], axis=1), test['label']\n",
    "    \n",
    "    # Running x_train and x_test (the inputs) into feature engineering.\n",
    "    x_train, x_test = feature_engineer(x_train), feature_engineer(x_test)\n",
    "    \n",
    "    categorical_columns = get_cat_cols(x_train)\n",
    "    non_categorical_columns = [x for x in x_train.columns if x not in categorical_columns]   \n",
    "    if scaler is not None:\n",
    "        x_train[non_categorical_columns] = scaler.fit_transform(x_train[non_categorical_columns])\n",
    "        x_test[non_categorical_columns] = scaler.transform(x_test[non_categorical_columns])\n",
    "    \n",
    "    if label_encoding:\n",
    "        x_train, x_test = label_encode(x_train, x_test)\n",
    "        features = x_train.columns\n",
    "    else:\n",
    "        x_train = pd.get_dummies(x_train)\n",
    "        x_test = pd.get_dummies(x_test)\n",
    "        print(\"Column mismatch {0}, {1}\".format(set(x_train.columns)- set(x_test.columns),  set(x_test.columns)- set(x_train.columns)))\n",
    "        features = list(set(x_train.columns) & set(x_test.columns))\n",
    "    print(f\"Number of features {len(features)}\")\n",
    "    x_train = x_train[features]\n",
    "    x_test = x_test[features]\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53057da-c1a9-4d86-9ff5-eb0a8d8d8aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_feature_importance(importance, columns):\n",
    "    feature_importance = pd.DataFrame(zip(columns, importance), columns=['Feature', 'Importance'])\n",
    "    feature_importance['Importance'] /= feature_importance['Importance'].sum()*0.01\n",
    "    return feature_importance.sort_values(by=\"Importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ca9b17-c0c6-4cd7-ae00-6835bb3f913b",
   "metadata": {},
   "source": [
    "## Preperation of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1038b331-e006-4cc3-bf52-5159497c3ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = input_train_test()\n",
    "categorical_columns = get_cat_cols(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e7dbee-608b-496e-9f57-b2b4e6f81668",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 10\n",
    "seed = 1\n",
    "num_round = 2000\n",
    "kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "X, Y, x_test, y_test = get_train_test(train, test, label_encoding=True, scaler= StandardScaler())\n",
    "importance_dict = {\n",
    "    \"feature\": X.columns\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c87f8f4-d675-40b2-b2b6-00c2744a8b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=1)\n",
    "clf.fit(X, Y)\n",
    "feature_importance = clf.feature_importances_\n",
    "importance_dict['train'] =  feature_importance\n",
    "# show_feature_importance(feature_importance, X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bf5d5da-4843-4299-a6d7-daacad1496ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sajepan\\AppData\\Local\\Temp/ipykernel_16544/3138433173.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for tr_idx, val_idx in tqdm(kf.split(X, Y), total=folds):\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16544/3138433173.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfeature_importances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mtr_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_idx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfolds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtr_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtr_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# x_val, y_val = X.iloc[val_idx], Y[val_idx]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\MasterThesisGPU\\lib\\site-packages\\tqdm\\__init__.py\u001b[0m in \u001b[0;36mtqdm_notebook\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m          \u001b[1;34m\"Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m          TqdmDeprecationWarning, stacklevel=2)\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_tqdm_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\MasterThesisGPU\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[0munit_scale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0munit_scale\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_printer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mncols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpbar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproxy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplayed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\MasterThesisGPU\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36mstatus_printer\u001b[1;34m(_, total, desc, ncols)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;31m# Prepare IPython progress bar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mIProgress\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# #187 #451 #558 #872\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             raise ImportError(\n\u001b[0m\u001b[0;32m    116\u001b[0m                 \u001b[1;34m\"IProgress not found. Please update jupyter and ipywidgets.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                 \u001b[1;34m\" See https://ipywidgets.readthedocs.io/en/stable\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "feature_importances = []\n",
    "\n",
    "for tr_idx, val_idx in tqdm(kf.split(X, Y), total=folds):\n",
    "    x_train, y_train = X.iloc[tr_idx], Y[tr_idx]\n",
    "    # x_val, y_val = X.iloc[val_idx], Y[val_idx]\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    feature_importances.append(clf.feature_importances_)\n",
    "\n",
    "feature_importance = np.mean(feature_importances, axis=0)\n",
    "importance_dict['train_10_fold'] =  feature_importance\n",
    "# show_feature_importance(feature_importance, X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
